{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sYZsCO9n0uyy"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00fa4db6a643474d919e4e946da856ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "# %pip install -q kagglehub\n",
        "import kagglehub\n",
        "\n",
        "kagglehub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t8NBecxp0uyz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/superpotato9/dalle-recognition-dataset?dataset_version_number=7...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 80.0M/13.4G [01:47<5:04:29, 784kB/s] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# THEN FEEL FREE TO DELETE THIS CELL.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# NOTEBOOK.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m superpotato9_dalle_recognition_dataset_path \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuperpotato9/dalle-recognition-dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m spectrewolf8_random_images_dataset_path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectrewolf8/random-images-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData source import complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/kagglehub/datasets.py:34\u001b[0m, in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     32\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[1;32m     33\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/kagglehub/registry.py:28\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/kagglehub/http_resolver.py:127\u001b[0m, in \u001b[0;36mDatasetHttpResolver.__call__\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    124\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(archive_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m \u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m _extract_archive(archive_path, out_path)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/kagglehub/clients.py:217\u001b[0m, in \u001b[0;36mKaggleApiV1Client.download_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m     \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[1;32m    220\u001b[0m     actual_md5_hash \u001b[38;5;241m=\u001b[39m to_b64_digest(hash_object)\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/kagglehub/clients.py:276\u001b[0m, in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mtotal_size, initial\u001b[38;5;241m=\u001b[39msize_read, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m progress_bar:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 276\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/snap/code/181/.local/share/virtualenvs/DMI_FYP_dj_primary-backend-cvNQsyiC/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[0;32m/usr/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m/usr/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "superpotato9_dalle_recognition_dataset_path = kagglehub.dataset_download(\n",
        "    \"superpotato9/dalle-recognition-dataset\"\n",
        ")\n",
        "spectrewolf8_random_images_dataset_path = kagglehub.dataset_download(\n",
        "    \"spectrewolf8/random-images-dataset\"\n",
        ")\n",
        "\n",
        "print(\"Data source import complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6287f8b3-8c48-4b8c-b40d-de9e6f9171fc",
        "_uuid": "6404d9ea-4947-4c49-bcdf-bd037dbb504b",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:42:19.994158Z",
          "iopub.status.busy": "2025-01-28T18:42:19.993694Z",
          "iopub.status.idle": "2025-01-28T18:42:52.908469Z",
          "shell.execute_reply": "2025-01-28T18:42:52.90754Z",
          "shell.execute_reply.started": "2025-01-28T18:42:19.994128Z"
        },
        "id": "ghomG8CZ0uy0",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "77b755af-24e2-41f7-8c18-7bec9bc12ba0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install opencv-python --upgrade\n",
        "# !pip install ultralytics --upgrade\n",
        "# !pip install torchmetrics --upgrade\n",
        "# !pip install grad-cam --upgrade\n",
        "# !pip install natsort --upgrade\n",
        "# !pip install Pillow --upgrade\n",
        "# !pip install wandb --upgrade\n",
        "# !pip install lightning --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3830d64-8d9b-45ff-bfa4-bcc203cb801a",
        "_uuid": "7ace74e4-e87d-4be8-938d-dae9e5cf61d1",
        "collapsed": false,
        "id": "QofR_RSW0uy1",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "### >Restart kernel!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8dfa77bd-a9bc-4f27-bbe0-0d9dc79cc1ce",
        "_uuid": "e3da3516-e71a-4b16-8188-4d5640d607be",
        "execution": {
          "iopub.execute_input": "2025-01-28T17:29:10.80591Z",
          "iopub.status.busy": "2025-01-28T17:29:10.805588Z",
          "iopub.status.idle": "2025-01-28T17:29:19.611566Z",
          "shell.execute_reply": "2025-01-28T17:29:19.610916Z",
          "shell.execute_reply.started": "2025-01-28T17:29:10.805862Z"
        },
        "id": "ZDLOaC1O0uy1",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as tnf\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from PIL import Image, ImageChops\n",
        "import os, shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torchmetrics import Accuracy, Precision, Recall, F1Score, ConfusionMatrix\n",
        "\n",
        "# from ultralytics import YOLO\n",
        "import hashlib\n",
        "from natsort import natsorted\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "709192b0-8a06-4b25-951a-37030585360e",
        "_uuid": "1ea37f95-d885-4287-bc78-616ddd0e23fa",
        "collapsed": false,
        "id": "UpAnme1n0uy2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "075afe5f-eb9b-4725-9193-8ab33f473bf3",
        "_uuid": "d8d9155e-6713-4245-8948-4b3702ba2f63",
        "collapsed": false,
        "id": "3A-YiVo_0uy2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Generate Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efb656e5-1394-4d91-888f-37681ba3cc99",
        "_uuid": "fad063e1-254b-4d1e-bbff-b377505fe2c5",
        "execution": {
          "iopub.execute_input": "2025-01-26T21:06:53.547706Z",
          "iopub.status.busy": "2025-01-26T21:06:53.547379Z",
          "iopub.status.idle": "2025-01-26T21:06:56.269677Z",
          "shell.execute_reply": "2025-01-26T21:06:56.268254Z",
          "shell.execute_reply.started": "2025-01-26T21:06:53.547681Z"
        },
        "id": "f886KmeN0uy2",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !rm -rf '/kaggle/working/temp_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40c61097-b271-477b-bb1e-8f4193cd3644",
        "_uuid": "5c05330d-0fa4-409d-aa75-9a0cd9755dbf",
        "execution": {
          "iopub.execute_input": "2025-01-26T21:07:05.389216Z",
          "iopub.status.busy": "2025-01-26T21:07:05.388843Z",
          "iopub.status.idle": "2025-01-26T21:10:25.756471Z",
          "shell.execute_reply": "2025-01-26T21:10:25.755263Z",
          "shell.execute_reply.started": "2025-01-26T21:07:05.389186Z"
        },
        "id": "LgUuYP1k0uy3",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#create directories\n",
        "!mkdir '/kaggle/working/temp_dataset'\n",
        "!mkdir '/kaggle/working/temp_dataset/real'\n",
        "!mkdir '/kaggle/working/temp_dataset/fake'\n",
        "!mkdir '/kaggle/working/models'\n",
        "\n",
        "# #copy real images\n",
        "# !cp -r '/kaggle/input/random-images-dataset/random_images_dataset/training/all_images/'* '/kaggle/working/temp_dataset/real/'\n",
        "# !cp -r '/kaggle/input/dalle-recognition-dataset/real/'* '/kaggle/working/temp_dataset/real/'\n",
        "!find '/kaggle/input/random-images-dataset/random_images_dataset/training/all_images/' -type f -print0 | xargs -0 cp -t '/kaggle/working/temp_dataset/real/'\n",
        "!find '/kaggle/input/dalle-recognition-dataset/real/' -type f -print0 | xargs -0 cp -t '/kaggle/working/temp_dataset/real/'\n",
        "\n",
        "# #copy fake images\n",
        "# !cp -r '/kaggle/input/dalle-recognition-dataset/fakeV2/fake-v2/'* '/kaggle/working/temp_dataset/fake/'\n",
        "!find '/kaggle/input/dalle-recognition-dataset/fakeV2/fake-v2/' -type f -print0 | xargs -0 cp -t '/kaggle/working/temp_dataset/fake/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8fa1e43a-f561-4947-b3c7-f0b1e33558a7",
        "_uuid": "95a2521c-a913-4bbb-8999-9cb469d8a78f",
        "execution": {
          "iopub.execute_input": "2025-01-26T21:40:57.220419Z",
          "iopub.status.busy": "2025-01-26T21:40:57.220075Z",
          "iopub.status.idle": "2025-01-26T21:40:57.900592Z",
          "shell.execute_reply": "2025-01-26T21:40:57.899315Z",
          "shell.execute_reply.started": "2025-01-26T21:40:57.220394Z"
        },
        "id": "s-tDRjOY0uy4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#remove unnecessary files\n",
        "!rm -rf '/kaggle/working/temp_dataset/real/r-art.txt'\n",
        "!rm -rf '/kaggle/working/temp_dataset/fake/sort'\n",
        "!rm -rf '/kaggle/working/temp_dataset/fake/dataset-metadata.json'\n",
        "!rm -rf '/kaggle/working/temp_dataset/fake/12479.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae9e00d1-ad1e-4525-bcb9-0659e1130c4d",
        "_uuid": "0861cc1c-9958-472c-9e87-ac6b95e309af",
        "execution": {
          "iopub.execute_input": "2025-01-28T17:29:19.613172Z",
          "iopub.status.busy": "2025-01-28T17:29:19.612676Z",
          "iopub.status.idle": "2025-01-28T17:29:19.944919Z",
          "shell.execute_reply": "2025-01-28T17:29:19.944199Z",
          "shell.execute_reply.started": "2025-01-28T17:29:19.61314Z"
        },
        "id": "X1ZFX9zf0uy4",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Print number of files\n",
        "real_files = [\n",
        "    os.path.join(\"/kaggle/working/temp_dataset/real\", f)\n",
        "    for f in os.listdir(\"/kaggle/working/temp_dataset/real\")\n",
        "    if os.path.isfile(os.path.join(\"/kaggle/working/temp_dataset/real\", f))\n",
        "]\n",
        "fake_files = [\n",
        "    os.path.join(\"/kaggle/working/temp_dataset/fake\", f)\n",
        "    for f in os.listdir(\"/kaggle/working/temp_dataset/fake\")\n",
        "    if os.path.isfile(os.path.join(\"/kaggle/working/temp_dataset/fake\", f))\n",
        "]\n",
        "\n",
        "print(f\"Number of real images: {len(real_files)}\")\n",
        "print(f\"Number of fake images: {len(fake_files)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "960e01ac-72f6-4f71-8605-790f9be9a03a",
        "_uuid": "161fbbf9-57c3-4918-bc60-b6d3dc60817c",
        "execution": {
          "iopub.execute_input": "2025-01-28T17:32:22.585068Z",
          "iopub.status.busy": "2025-01-28T17:32:22.584638Z",
          "iopub.status.idle": "2025-01-28T17:33:06.376534Z",
          "shell.execute_reply": "2025-01-28T17:33:06.375809Z",
          "shell.execute_reply.started": "2025-01-28T17:32:22.585037Z"
        },
        "id": "RpVmL4X70uy5",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "def is_valid_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            # Check image size\n",
        "            if img.width * img.height > 178956970:  # PIL's max pixel limit\n",
        "                print(f\"Oversized image: {file_path}\")\n",
        "                return False\n",
        "\n",
        "            # Additional checks\n",
        "            img.verify()  # Verify the image is not corrupted\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Invalid image {file_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Modify your dataset loading to skip invalid images\n",
        "valid_image_paths_1 = [path for path in real_files if is_valid_image(path)]\n",
        "valid_image_paths_2 = [path for path in fake_files if is_valid_image(path)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b0338e30-c523-4d01-a12c-1abcd1c1da04",
        "_uuid": "5d9ecd4c-7d76-4aab-adb6-52ac97bfa08b",
        "collapsed": false,
        "id": "qCI2N5cZ0uy5",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4810eb2f-6c7a-4e06-98a8-45e51b286800",
        "_uuid": "3535523f-162f-433d-8d03-06c5929aca12",
        "execution": {
          "iopub.execute_input": "2025-01-28T17:33:06.377839Z",
          "iopub.status.busy": "2025-01-28T17:33:06.377589Z",
          "iopub.status.idle": "2025-01-28T17:33:06.382152Z",
          "shell.execute_reply": "2025-01-28T17:33:06.381421Z",
          "shell.execute_reply.started": "2025-01-28T17:33:06.377818Z"
        },
        "id": "2G5MCfBY0uy5",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "052e6e29-e382-48bd-813f-5bd362164497",
        "_uuid": "579b22f0-7110-46d3-a547-fefaf675ca86",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:51:21.642613Z",
          "iopub.status.busy": "2025-01-28T18:51:21.6423Z",
          "iopub.status.idle": "2025-01-28T18:51:21.649136Z",
          "shell.execute_reply": "2025-01-28T18:51:21.648372Z",
          "shell.execute_reply.started": "2025-01-28T18:51:21.64259Z"
        },
        "id": "zqFQ3eDP0uy5",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class AiGenDataset(Dataset):\n",
        "    def __init__(self, image_dir, cap=1000, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir (str): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.samples_cap = cap\n",
        "\n",
        "        # Assuming there are two folders: 'real' and 'deepfake' in 'dataset' directory\n",
        "        for label in [\"real\", \"fake\"]:\n",
        "            label_dir = os.path.join(image_dir, label)\n",
        "\n",
        "            # Iterate over all images in 'real' and 'fake' directories\n",
        "            for idx, img_file in enumerate(os.listdir(label_dir)):\n",
        "                if idx > self.samples_cap:\n",
        "                    break\n",
        "                img_path = os.path.join(label_dir, img_file)\n",
        "                self.image_paths.append(img_path)\n",
        "\n",
        "                # Assign labels: 'real' -> 0, 'fake' -> 1\n",
        "                self.labels.append(0 if label == \"real\" else 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # try:\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load image and convert it to RGB\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Apply the transform, if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Error loading image {img_path}: {e}\")\n",
        "        #     image = Image.new('RGB', (224, 224), color='black')\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43f70544-3d4e-4e10-899b-670f65ac5bc1",
        "_uuid": "d8da1e5e-c924-4c55-b6d3-4f3a28f7e2b7",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:51:25.964031Z",
          "iopub.status.busy": "2025-01-28T18:51:25.963632Z",
          "iopub.status.idle": "2025-01-28T18:51:26.001078Z",
          "shell.execute_reply": "2025-01-28T18:51:26.000338Z",
          "shell.execute_reply.started": "2025-01-28T18:51:25.963996Z"
        },
        "id": "f4G_4GBK0uy6",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "645933b3-d015-45f7-dbc5-dc3fa5634ca8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# /kaggle/working/dataset/\n",
        "# ├── real/\n",
        "# └── fake/\n",
        "\n",
        "# Define the dataset with all data\n",
        "dataset = AiGenDataset(image_dir=\"/kaggle/working/temp_dataset\", transform=transform)\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create DataLoaders for each set\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Print details for confirmation\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "print(f\"Train loader: {train_loader}\")\n",
        "print(f\"Validation loader: {val_loader}\")\n",
        "print(f\"Test loader: {test_loader}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d8d1ea8-adf6-4f87-9262-b084d5d3a5f5",
        "_uuid": "98dc2ac7-7c93-4e60-bb90-549bd0eeda25",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:32:55.924925Z",
          "iopub.status.busy": "2025-01-28T18:32:55.924544Z",
          "iopub.status.idle": "2025-01-28T18:32:57.455433Z",
          "shell.execute_reply": "2025-01-28T18:32:57.454735Z",
          "shell.execute_reply.started": "2025-01-28T18:32:55.92489Z"
        },
        "id": "Jr8lMz_F0uy6",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torchvision.models import ResNeXt101_32X8D_Weights\n",
        "\n",
        "# model = models.resnext50_32x4d()\n",
        "# model = models.resnext101_32x8d()\n",
        "\n",
        "model = models.resnext101_32x8d(weights=ResNeXt101_32X8D_Weights.DEFAULT)\n",
        "\n",
        "# Modify the last layer to match the number of classes (real or fake)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: real and fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec515add-5b9d-42d7-9895-0e504425f6e8",
        "_uuid": "a8ba8025-1bba-4f0a-85e3-35184c35f658",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:33:01.178333Z",
          "iopub.status.busy": "2025-01-28T18:33:01.17798Z",
          "iopub.status.idle": "2025-01-28T18:33:01.185248Z",
          "shell.execute_reply": "2025-01-28T18:33:01.184584Z",
          "shell.execute_reply.started": "2025-01-28T18:33:01.178302Z"
        },
        "id": "lEhlc1Vh0uy7",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc95645f-5427-4e1d-85c0-900fc94af981",
        "_uuid": "4ccd6cd4-4d7d-43aa-87ef-ee8d9587adc0",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:33:02.48098Z",
          "iopub.status.busy": "2025-01-28T18:33:02.480654Z",
          "iopub.status.idle": "2025-01-28T18:33:02.581039Z",
          "shell.execute_reply": "2025-01-28T18:33:02.580294Z",
          "shell.execute_reply.started": "2025-01-28T18:33:02.480956Z"
        },
        "id": "CcwFuyLJ0uy7",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(device)\n",
        "# print(device,'\\n', model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d417dc78-03b6-46db-91e2-3de4a3dc1244",
        "_uuid": "cec20a30-186b-4fd5-bfba-56cf4f3ac5da",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:33:03.459851Z",
          "iopub.status.busy": "2025-01-28T18:33:03.4595Z",
          "iopub.status.idle": "2025-01-28T18:33:03.46948Z",
          "shell.execute_reply": "2025-01-28T18:33:03.468834Z",
          "shell.execute_reply.started": "2025-01-28T18:33:03.459821Z"
        },
        "id": "xCe9uUbR0uy7",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize metrics\n",
        "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=2).to(device)\n",
        "precision_metric = Precision(task=\"multiclass\", num_classes=2, average=\"macro\").to(device)\n",
        "recall_metric = Recall(task=\"multiclass\", num_classes=2, average=\"macro\").to(device)\n",
        "f1_metric = F1Score(task=\"multiclass\", num_classes=2, average=\"macro\").to(device)\n",
        "confusion_matrix_metric = ConfusionMatrix(task=\"multiclass\", num_classes=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8d040333-9094-40d1-a433-25346ab8f8cd",
        "_uuid": "14b261f2-830c-4ef4-b2e6-1165fd36230c",
        "collapsed": false,
        "id": "5ysI7q8O0uy7",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Train loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d6789b0-46df-48ea-81fe-7f28e3c2478e",
        "_uuid": "1f30ae58-abb7-4650-b3ad-37868862f37c",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:33:06.306545Z",
          "iopub.status.busy": "2025-01-28T18:33:06.30625Z",
          "iopub.status.idle": "2025-01-28T18:33:11.707874Z",
          "shell.execute_reply": "2025-01-28T18:33:11.706712Z",
          "shell.execute_reply.started": "2025-01-28T18:33:06.306522Z"
        },
        "id": "URK3bCt30uy_",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Reset metrics at start of epoch\n",
        "    accuracy_metric.reset()\n",
        "    precision_metric.reset()\n",
        "    recall_metric.reset()\n",
        "    f1_metric.reset()\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # Update metrics batch by batch\n",
        "        accuracy_metric.update(outputs, labels)\n",
        "        precision_metric.update(outputs, labels)\n",
        "        recall_metric.update(outputs, labels)\n",
        "        f1_metric.update(outputs, labels)\n",
        "\n",
        "    # Compute epoch metrics\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = accuracy_metric.compute() * 100\n",
        "    epoch_precision = precision_metric.compute()\n",
        "    epoch_recall = recall_metric.compute()\n",
        "    epoch_f1 = f1_metric.compute()\n",
        "\n",
        "    print(\n",
        "        f\"--------\\nEpoch [{epoch + 1}/{num_epochs}]\"\n",
        "        f\"\\nTrain Loss: {epoch_loss:.4f}\"\n",
        "        f\"\\nTrain Metrics:\"\n",
        "        f\"\\n  Accuracy: {epoch_acc:.2f}%\"\n",
        "        f\"\\n  Precision: {epoch_precision:.2f}\"\n",
        "        f\"\\n  Recall: {epoch_recall:.2f}\"\n",
        "        f\"\\n  F1 Score: {epoch_f1:.2f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f392619f-cba0-419b-9693-c6e8393fe0b9",
        "_uuid": "a9113657-a00c-4c6e-8721-1c5578357cf8",
        "collapsed": false,
        "id": "Hu1kyanq0uy_",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Val loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e4e702e-1fd3-441f-8008-6933b238c91d",
        "_uuid": "f08a3ac9-0179-4c08-8ebb-924b923ed121",
        "execution": {
          "iopub.execute_input": "2025-01-28T19:09:51.392103Z",
          "iopub.status.busy": "2025-01-28T19:09:51.391705Z",
          "iopub.status.idle": "2025-01-28T19:09:51.834548Z",
          "shell.execute_reply": "2025-01-28T19:09:51.833285Z",
          "shell.execute_reply.started": "2025-01-28T19:09:51.392074Z"
        },
        "id": "atg1RlLU0uy_",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d2247bd9-84d5-4f6a-968c-8587c123b285",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "val_loss = 0.0\n",
        "\n",
        "# Reset all metrics at the start of validation\n",
        "accuracy_metric.reset()\n",
        "precision_metric.reset()\n",
        "recall_metric.reset()\n",
        "f1_metric.reset()\n",
        "confusion_matrix_metric.reset()\n",
        "\n",
        "with torch.no_grad():  # Disable gradient computation\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        # Update metrics batch by batch\n",
        "        accuracy_metric.update(outputs, labels)\n",
        "        precision_metric.update(outputs, labels)\n",
        "        recall_metric.update(outputs, labels)\n",
        "        f1_metric.update(outputs, labels)\n",
        "        confusion_matrix_metric.update(outputs, labels)\n",
        "\n",
        "# Compute final metrics\n",
        "val_loss = val_loss / len(val_loader)\n",
        "val_accuracy = accuracy_metric.compute() * 100\n",
        "val_precision = precision_metric.compute()\n",
        "val_recall = recall_metric.compute()\n",
        "val_f1 = f1_metric.compute()\n",
        "val_confusion_matrix = confusion_matrix_metric.compute()\n",
        "\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
        "print(f\"Precision: {val_precision:.2f}, Recall: {val_recall:.2f}, F1 Score: {val_f1:.2f}\")\n",
        "print(f\"Confusion Matrix:\\n{val_confusion_matrix.cpu().numpy()}\")\n",
        "\n",
        "# Confusion matrix\n",
        "# [[TN  FP]\n",
        "#  [FN  TP]]\n",
        "\n",
        "# TN = True Negatives\n",
        "# FP = False Positives\n",
        "# FN = False Negatives\n",
        "# TP = True Positives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "604b75fd-b95e-44d8-85bd-57aaada85262",
        "_uuid": "d5417bdc-e26c-466c-b9b8-d9dd7852e6b1",
        "collapsed": false,
        "id": "QEUwJhIF0uzA",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Test loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c910cc1a-4eeb-4b67-8432-eab0ca0b28e5",
        "_uuid": "74d94bf2-cec9-4144-a784-d4f77dd7b069",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:26:21.447296Z",
          "iopub.status.busy": "2025-01-28T18:26:21.446978Z",
          "iopub.status.idle": "2025-01-28T18:26:21.506242Z",
          "shell.execute_reply": "2025-01-28T18:26:21.505458Z",
          "shell.execute_reply.started": "2025-01-28T18:26:21.447272Z"
        },
        "id": "3UJizX1N0uzA",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "test_loss = 0.0\n",
        "\n",
        "# Reset all metrics before testing\n",
        "accuracy_metric.reset()\n",
        "precision_metric.reset()\n",
        "recall_metric.reset()\n",
        "f1_metric.reset()\n",
        "confusion_matrix_metric.reset()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Update metrics batch by batch\n",
        "        accuracy_metric.update(outputs, labels)\n",
        "        precision_metric.update(outputs, labels)\n",
        "        recall_metric.update(outputs, labels)\n",
        "        f1_metric.update(outputs, labels)\n",
        "        confusion_matrix_metric.update(outputs, labels)\n",
        "\n",
        "# Compute final metrics\n",
        "test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_metric.compute() * 100\n",
        "test_precision = precision_metric.compute()\n",
        "test_recall = recall_metric.compute()\n",
        "test_f1 = f1_metric.compute()\n",
        "test_confusion_matrix = confusion_matrix_metric.compute()\n",
        "\n",
        "print(\n",
        "    f\"Test Metrics:\"\n",
        "    f\"\\n  Loss: {test_loss:.4f}\"\n",
        "    f\"\\n  Accuracy: {test_accuracy:.2f}%\"\n",
        "    f\"\\n  Precision: {test_precision:.2f}\"\n",
        "    f\"\\n  Recall: {test_recall:.2f}\"\n",
        "    f\"\\n  F1 Score: {test_f1:.2f}\"\n",
        ")\n",
        "print(f\"Confusion Matrix:\\n{test_confusion_matrix.cpu().numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "82f19cd1-bae1-4a8a-a197-11047acc8da4",
        "_uuid": "6e451ee8-14e9-4bdf-9d96-9a006fe11ac4",
        "collapsed": false,
        "id": "UXsLwZTs0uzA",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Exporting model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "194c87f5-07c6-4d39-8a8a-a0db95fbd676",
        "_uuid": "a0d16e29-97fb-43ac-8bf2-53598da84a00",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:27:24.696383Z",
          "iopub.status.busy": "2025-01-28T18:27:24.696081Z",
          "iopub.status.idle": "2025-01-28T18:27:25.150888Z",
          "shell.execute_reply": "2025-01-28T18:27:25.149806Z",
          "shell.execute_reply.started": "2025-01-28T18:27:24.696358Z"
        },
        "id": "mJkgzC7a0uzA",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), '/kaggle/working/model/acc99.49_test-1_deepfake_detector_resnext50.pth')\n",
        "torch.save(model, \"/kaggle/working/models/acc94.00_test-1.0_AI_image_detector_resnext101_32x8d.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "38594423-d5ee-4342-92f9-d004ff3224c0",
        "_uuid": "b06fe734-e5a1-4ba6-97c6-bccf4f4d55df",
        "collapsed": false,
        "id": "WVBFyUe50uzB",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "## Manual Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f1a59a4-78e6-479d-9173-b7fe5f9b896f",
        "_uuid": "0ee26b8d-916e-4ede-b228-ca79fa8f73d0",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:27:29.65262Z",
          "iopub.status.busy": "2025-01-28T18:27:29.652296Z",
          "iopub.status.idle": "2025-01-28T18:27:29.658026Z",
          "shell.execute_reply": "2025-01-28T18:27:29.657246Z",
          "shell.execute_reply.started": "2025-01-28T18:27:29.652593Z"
        },
        "id": "FcGhrNDh0uzB",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_test_image(image_path, show_image=False):\n",
        "    if show_image:\n",
        "        cv_img = cv2.imread(image_path)\n",
        "\n",
        "        # Convert the image from BGR to RGB for displaying with matplotlib\n",
        "        cv_img_rgb = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Display the image with detected faces\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(cv_img_rgb)\n",
        "        plt.axis(\"off\")  # Hide axis\n",
        "        plt.title(f\"Test image\")\n",
        "        plt.show()\n",
        "\n",
        "    #     Define the transformations (should be the same as used in training)\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((224, 224)),  # Resize the image to the input size of the model\n",
        "            transforms.ToTensor(),  # Convert image to tensor\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "            ),  # Normalize as per the pre-trained model's requirements\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Load the image\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Apply the transformations\n",
        "    image = transform(image)\n",
        "\n",
        "    # Add a batch dimension (models expect a batch of images, even if it's just one image)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "398f1864-6bef-49bc-977b-a6bd535710ca",
        "_uuid": "5f106557-31bd-4993-90de-d5be5604b0bc",
        "execution": {
          "iopub.execute_input": "2025-01-28T18:29:04.400743Z",
          "iopub.status.busy": "2025-01-28T18:29:04.40041Z",
          "iopub.status.idle": "2025-01-28T18:29:04.742604Z",
          "shell.execute_reply": "2025-01-28T18:29:04.741921Z",
          "shell.execute_reply.started": "2025-01-28T18:29:04.400693Z"
        },
        "id": "ZpC4koUg0uzC",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "image_path = \"/kaggle/input/dalle-recognition-dataset/fakeV2/fake-v2/10005.jpg\"\n",
        "image = load_test_image(image_path=image_path, show_image=True)\n",
        "# Make prediction\n",
        "with torch.no_grad():  # No need to compute gradients for inference\n",
        "    image = image.to(device)\n",
        "    output = model(image)  # Forward pass\n",
        "\n",
        "    # Apply softmax to get probabilities\n",
        "    probabilities = tnf.softmax(output, dim=1)\n",
        "\n",
        "    # Get the class with the highest probability\n",
        "    confidence, predicted = torch.max(probabilities, 1)  # Get the class with highest probability\n",
        "\n",
        "# Convert the prediction to a label (assuming you have a mapping of class indices to labels)\n",
        "label_map = {0: \"real\", 1: \"fake\"}  # Adjust based on your dataset\n",
        "predicted_label = label_map[predicted.item()]\n",
        "\n",
        "# Print predicted label and confidence score\n",
        "confidence_score = confidence.item()\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "print(f\"Confidence score: {confidence_score*100:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a378654c-159a-41e0-b32e-e70040b2eeda",
        "_uuid": "b0823435-9642-492d-8c6e-0f8778b243c8",
        "collapsed": false,
        "id": "ff5gBB1S0uzC",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "source": [
        "# Load Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83af0487-3b54-4c09-ac32-b7ab5fac9f18",
        "_uuid": "9de33d47-fe31-4c7d-b6d1-536da4f0564b",
        "id": "qwI8vypI0uzC",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Assuming your model is already defined and loaded\n",
        "# model = models.resnext50_32x4d()  # Replace with your actual model definition\n",
        "loaded_model = torch.load(\n",
        "    \"/kaggle/working/model/acc98.00_test-2.1_CROPS_deepfake_detector_resnext101_32x8d.pth\",\n",
        "    map_location=\"cpu\",\n",
        "    weights_only=False,\n",
        ")  # Load the trained model weights\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# If using GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loaded_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aildTig0uzC"
      },
      "source": [
        "# Shifting to pytorch lightening\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-28T18:47:30.802801Z",
          "iopub.status.busy": "2025-01-28T18:47:30.802401Z",
          "iopub.status.idle": "2025-01-28T18:47:31.779834Z",
          "shell.execute_reply": "2025-01-28T18:47:31.778937Z",
          "shell.execute_reply.started": "2025-01-28T18:47:30.80277Z"
        },
        "id": "Cd8zJ8dZ0uzC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# import pytorch_lightning as pl\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torchvision.models as models\n",
        "# from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
        "# from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# class AIImageDetector(pl.LightningModule):\n",
        "#     def __init__(self, learning_rate=0.001):\n",
        "#         super().__init__()\n",
        "#         # Load the ResNeXt model\n",
        "#         self.model = models.resnext101_64x4d(weights='DEFAULT')\n",
        "\n",
        "#         # Modify the last layer for binary classification\n",
        "#         num_ftrs = self.model.fc.in_features\n",
        "#         self.model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#         # Save hyperparameters\n",
        "#         self.save_hyperparameters()\n",
        "\n",
        "#         # Loss function\n",
        "#         self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#         # Metrics\n",
        "#         self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n",
        "#         self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n",
        "#         self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n",
        "\n",
        "#         self.train_precision = Precision(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.val_precision = Precision(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.test_precision = Precision(task=\"multiclass\", num_classes=2, average='macro')\n",
        "\n",
        "#         self.train_recall = Recall(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.val_recall = Recall(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.test_recall = Recall(task=\"multiclass\", num_classes=2, average='macro')\n",
        "\n",
        "#         self.train_f1 = F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.val_f1 = F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
        "#         self.test_f1 = F1Score(task=\"multiclass\", num_classes=2, average='macro')\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.model(x)\n",
        "\n",
        "#     def training_step(self, batch, batch_idx):\n",
        "#         x, y = batch\n",
        "#         logits = self(x)\n",
        "#         loss = self.criterion(logits, y)\n",
        "\n",
        "#         # Calculate and log metrics\n",
        "#         self.train_accuracy(logits, y)\n",
        "#         self.train_precision(logits, y)\n",
        "#         self.train_recall(logits, y)\n",
        "#         self.train_f1(logits, y)\n",
        "\n",
        "#         self.log('train_loss', loss, prog_bar=True)\n",
        "#         self.log('train_accuracy', self.train_accuracy, prog_bar=True)\n",
        "#         self.log('train_precision', self.train_precision)\n",
        "#         self.log('train_recall', self.train_recall)\n",
        "#         self.log('train_f1', self.train_f1)\n",
        "\n",
        "#         return loss\n",
        "\n",
        "#     def validation_step(self, batch, batch_idx):\n",
        "#         x, y = batch\n",
        "#         logits = self(x)\n",
        "#         loss = self.criterion(logits, y)\n",
        "\n",
        "#         # Calculate and log metrics\n",
        "#         self.val_accuracy(logits, y)\n",
        "#         self.val_precision(logits, y)\n",
        "#         self.val_recall(logits, y)\n",
        "#         self.val_f1(logits, y)\n",
        "\n",
        "#         self.log('val_loss', loss, prog_bar=True)\n",
        "#         self.log('val_accuracy', self.val_accuracy, prog_bar=True)\n",
        "#         self.log('val_precision', self.val_precision)\n",
        "#         self.log('val_recall', self.val_recall)\n",
        "#         self.log('val_f1', self.val_f1)\n",
        "\n",
        "#         return loss\n",
        "\n",
        "#     def test_step(self, batch, batch_idx):\n",
        "#         x, y = batch\n",
        "#         logits = self(x)\n",
        "#         loss = self.criterion(logits, y)\n",
        "\n",
        "#         # Calculate and log metrics\n",
        "#         self.test_accuracy(logits, y)\n",
        "#         self.test_precision(logits, y)\n",
        "#         self.test_recall(logits, y)\n",
        "#         self.test_f1(logits, y)\n",
        "\n",
        "#         self.log('test_loss', loss, prog_bar=True)\n",
        "#         self.log('test_accuracy', self.test_accuracy, prog_bar=True)\n",
        "#         self.log('test_precision', self.test_precision)\n",
        "#         self.log('test_recall', self.test_recall)\n",
        "#         self.log('test_f1', self.test_f1)\n",
        "\n",
        "#         return loss\n",
        "\n",
        "#     def configure_optimizers(self):\n",
        "#         optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
        "#         return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-28T18:47:34.744787Z",
          "iopub.status.busy": "2025-01-28T18:47:34.744406Z",
          "iopub.status.idle": "2025-01-28T18:47:34.749626Z",
          "shell.execute_reply": "2025-01-28T18:47:34.748594Z",
          "shell.execute_reply.started": "2025-01-28T18:47:34.744748Z"
        },
        "id": "XK_aCUYS0uzD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Create PyTorch Lightning DataModule\n",
        "# class AIImageDataModule(pl.LightningDataModule):\n",
        "#     def __init__(self, train_loader, val_loader, test_loader):\n",
        "#         super().__init__()\n",
        "#         self.train_loader = train_loader\n",
        "#         self.val_loader = val_loader\n",
        "#         self.test_loader = test_loader\n",
        "\n",
        "#     def train_dataloader(self):\n",
        "#         return self.train_loader\n",
        "\n",
        "#     def val_dataloader(self):\n",
        "#         return self.val_loader\n",
        "\n",
        "#     def test_dataloader(self):\n",
        "#         return self.test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-28T18:47:36.777687Z",
          "iopub.status.busy": "2025-01-28T18:47:36.777348Z",
          "iopub.status.idle": "2025-01-28T18:47:36.7837Z",
          "shell.execute_reply": "2025-01-28T18:47:36.782947Z",
          "shell.execute_reply.started": "2025-01-28T18:47:36.777656Z"
        },
        "id": "ZPUmKnJb0uzD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# from pytorch_lightning.loggers import WandbLogger  # or TensorBoardLogger\n",
        "\n",
        "# # Initialize logger\n",
        "# wandb_logger = WandbLogger(project='ai-image-detection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "",
            "75a8d0ae9159416da04c75457436fcb3",
            "f25828bab9854cde8281b1c23c07c176"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-01-28T18:51:37.515454Z",
          "iopub.status.busy": "2025-01-28T18:51:37.515159Z",
          "iopub.status.idle": "2025-01-28T19:08:42.385817Z",
          "shell.execute_reply": "2025-01-28T19:08:42.385048Z",
          "shell.execute_reply.started": "2025-01-28T18:51:37.515431Z"
        },
        "id": "FJxnzxgT0uzD",
        "outputId": "af32a8da-5a10-4f05-f607-5dc9caee427e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # Create the data module\n",
        "# data_module = AIImageDataModule(train_loader, val_loader, test_loader)\n",
        "\n",
        "# # Create the model\n",
        "# model = AIImageDetector(learning_rate=0.001)\n",
        "\n",
        "# # Define callbacks\n",
        "# checkpoint_callback = ModelCheckpoint(\n",
        "#     monitor='val_accuracy',\n",
        "#     dirpath='checkpoints/',\n",
        "#     filename='ai-detector-{epoch:02d}-{val_accuracy:.2f}',\n",
        "#     save_top_k=3,\n",
        "#     mode='max'\n",
        "# )\n",
        "\n",
        "# early_stop_callback = EarlyStopping(\n",
        "#     monitor='val_loss',\n",
        "#     patience=5,\n",
        "#     mode='min'\n",
        "# )\n",
        "\n",
        "# # Initialize trainer\n",
        "# trainer = pl.Trainer(\n",
        "#     max_epochs=15,\n",
        "#     accelerator='auto',  # Automatically detect GPU/CPU\n",
        "#     devices=1,\n",
        "#     callbacks=[checkpoint_callback, early_stop_callback],\n",
        "#     # logger=wandb_logger\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# trainer.fit(model, data_module)\n",
        "\n",
        "# # Test the model\n",
        "# trainer.test(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-28T19:09:37.008861Z",
          "iopub.status.busy": "2025-01-28T19:09:37.008532Z",
          "iopub.status.idle": "2025-01-28T19:09:37.403988Z",
          "shell.execute_reply": "2025-01-28T19:09:37.403227Z",
          "shell.execute_reply.started": "2025-01-28T19:09:37.008837Z"
        },
        "id": "aM5iwATq0uzD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# torch.save(model, '/kaggle/working/models/acc94.00_test-2.0_AI_image_detector_resnext101_32x8d.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2biGuE2a0uzE",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "AIGM_detectection-ResNext-FYP-P2.ipynb",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 2811380,
          "sourceId": 7501727,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6501494,
          "sourceId": 10500820,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30840,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "DMI_FYP_dj_primary-backend-cvNQsyiC",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
